# XAI&I: Closing the Accuracy Gap Between Self-Explanatory AI and Black Box Convolutional Neural Networks
## Aims and Objectives

The primary aim of this project was to build upon and enhance Grange et al.â€™s self-explanatory XAI model, with the intention of improving classification accuracy to match or surpass that of a black-box model, whilst preserving the capacity to predict expert-iintelligible features. This endeavour aimed to further deepen upon the mutual understanding of human and AI feature abstractions.

To meet this aim, the first objective involved the development of an additional network classifier layer, of which could provide some degree of flexibility for the network to continue learning. Once completed, the evaluation of classification accuracy and concept alignment could be explored through the analysis of results using three primary research methods: manipulation of network training variables, removal of a single weakly aligned feature value from the training data, and alteration of a single feature/concept to binary or continuous/scalar in the training data.
Meeting these requirements, necessitates the development of tools to expedite data analysis, such as automation and data visualisation, enabling a deeper understanding of the effects of the proposed research methods.
